{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['IS_DEV_LOGGING'] = str(1)\n",
    "os.environ['ENABLE_LOGGING'] = str(0)\n",
    "\n",
    "\n",
    "PDF_PATH = Path(\"<REPLACE THIS WITH PATH TO PDF TO READ>\") \n",
    "PAGE_PDF_START = 0\n",
    "PAGE_PDF_END = 999\n",
    "OUTPUT_WAV_PATH = f\"<OUTPUT NAME HERE>.wav\"\n",
    "SPEAKER_WAV_FILES = [\n",
    "    \"<INPUT PATH TO SPEAKER WAV FILE>\",\n",
    "    \"<INPUT PATH TO SPEAKER WAV FILE 2>\",\n",
    "    \"...\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "import re\n",
    "\n",
    "from wtpsplit import SaT\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "from TTS.api import TTS\n",
    "from src.text_processors.str_to_sentences import split_into_sentences # so far better than nltk punkt\n",
    "from src.parsers.pymupdf_parser import PyMuPDFParser\n",
    "from src.text_processors.pre_processor import PreProcessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "with PyMuPDFParser(PDF_PATH) as pdf_parser:\n",
    "    pdf_parser.remove_all_links()\n",
    "    result = pdf_parser.extract_text_between_pages(PAGE_PDF_START, PAGE_PDF_END)\n",
    "    \n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CLEAN TEXT FROM UNWANTED CHARS AND SPLIT INTO SENTENCES** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "pre_processor = PreProcessor()\n",
    "\n",
    "res_clean = pre_processor.remove_unwanted_nonascii_chars(result)\n",
    "\n",
    "res_clean = pre_processor.remove_extra_periods(res_clean)\n",
    "res_clean = pre_processor.remove_leading_commas(res_clean)\n",
    "\n",
    "res_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "sat = SaT(\"sat-12l-sm\", style_or_domain=\"nl\", language=\"nl\") # TODO: leaks VRAM\n",
    "sat.half().to(\"cuda\")\n",
    "res_clean = list(sat.split(res_clean))\n",
    "\n",
    "# Move model to CPU\n",
    "sat.model.model.cpu()\n",
    "sat.model.cpu()\n",
    "sat.cpu()\n",
    "\n",
    "# Delete model\n",
    "del sat.model.model \n",
    "del sat.model\n",
    "del sat.tokenizer\n",
    "del sat\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# del sat\n",
    "gc.collect()\n",
    "\n",
    "res_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "dev = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"{dev=}\")\n",
    "\n",
    "# TODO: https://docs.coqui.ai/en/dev/models/xtts.html --> check this site for more info about XTTS_v2\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_dir = Path(OUTPUT_WAV_PATH.split(\".\")[0]+\"_dir\")\n",
    "if not os.path.exists(synth_dir):\n",
    "    os.mkdir(synth_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "filename = OUTPUT_WAV_PATH.split(\".\")[0]\n",
    "ext = \".\"+OUTPUT_WAV_PATH.split(\".\")[1]\n",
    "audio_paths = []\n",
    "\n",
    "for i, sent in enumerate(res_clean):\n",
    "    audio_paths.append(synth_dir / Path(filename+f\"_{i}\"+ext))\n",
    "\n",
    "\n",
    "for i, audio_path in enumerate(tqdm(audio_paths)):\n",
    "    if not os.path.exists(audio_path):\n",
    "        # Strip to remove added whitespaces by sentence splitter model. \n",
    "        # Then remove trailing punctuations in the hope that the XTTS model outputs better wav files\n",
    "        res_clean[i] = pre_processor.remove_punctuations_at_end(res_clean[i].strip()) \n",
    "        \n",
    "        tts.tts_to_file(\n",
    "            text=res_clean[i], \n",
    "            speaker_wav=SPEAKER_WAV_FILES, \n",
    "            language=\"nl\", \n",
    "            file_path=audio_path, \n",
    "            split_sentences=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "\n",
    "def concatenate_audio_wave(audio_clip_paths, output_path):\n",
    "    \"\"\"Concatenates several audio files into one audio file using Python's built-in wav module\n",
    "    and save it to `output_path`. Note that extension (wav) must be added to `output_path`\"\"\"\n",
    "    data = []\n",
    "    for clip in audio_clip_paths:\n",
    "        w = wave.open(clip, \"rb\")\n",
    "        data.append([w.getparams(), w.readframes(w.getnframes())])\n",
    "        w.close()\n",
    "    output = wave.open(output_path, \"wb\")\n",
    "    output.setparams(data[0][0])\n",
    "    for i in range(len(data)):\n",
    "        output.writeframes(data[i][1])\n",
    "    output.close()\n",
    "\n",
    "concatenate_audio_wave(list(map(str, audio_paths)), str(synth_dir / OUTPUT_WAV_PATH))\n",
    "\n",
    "# remove audio sounds after merge\n",
    "for audio_path in audio_paths:\n",
    "    os.remove(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio \n",
    "from IPython.core.display import display\n",
    "def autoplay_audio():\n",
    "    display(Audio(synth_dir / OUTPUT_WAV_PATH, autoplay=True))\n",
    "autoplay_audio()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
